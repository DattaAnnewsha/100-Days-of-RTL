{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DattaAnnewsha/100-Days-of-RTL/blob/main/EE599_ML_Systems_HW6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxH3R-8OZOpk"
      },
      "source": [
        "# HW6 EE599 Systems for Machine Learning, Fall 2023\n",
        "University of Southern California\n",
        "\n",
        "Instructors: Arash Saifhashemi, Murali Annavaram\n",
        "\n",
        "In this homework assignment, we're going to implement DP-SGD for neural networks! Recall from the class that classical ML models possessed convenient properties such as Convexity and L-Lipschitzness which make the DP analysis easy. However, modern neural networks, like the one we'll be working with, does not have these properties. Thus, we need to modify the training algorithm, gradient descent, so that the trained model is DP.\n",
        "\n",
        "## Prerequisites:\n",
        "\n",
        "Set the runtime type to GPU. (Runtime -> Change Runtime Type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQQk25oQCo8f"
      },
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "Create a folder named `HW6` under `ML_Systems` in your Google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezmjLOr6Co8f",
        "outputId": "8a8364db-c004-4a74-de81-49fe30d17299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "import sys, os\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/ML_Systems/HW6/data\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1ODkkuwZTSD"
      },
      "source": [
        "## Initial Setup\n",
        "\n",
        "This section imports all required packages from PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnT0mf2l0hUC",
        "outputId": "ab60a0a3-f6d7-41f8-e3f4-ab2ccad5dcfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x79f23e30a790>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B5DlxLjCo8g"
      },
      "source": [
        "**Reminder:** set the runtime type to \"GPU\", or your code will run much more slowly on a CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22wBDD60Co8h"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQA2aMuNbv48"
      },
      "source": [
        "Define model architecture and prepare dataset, which are the same as the previous homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km-kc-wa0n5d"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # Define the layers of the neural network architecture\n",
        "\n",
        "        # First convolutional layer: 3 input channels, 6 output channels, kernel size 5x5\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
        "\n",
        "        # Max pooling layer with kernel size 2x2 and stride 2\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Second convolutional layer: 6 input channels, 16 output channels, kernel size 5x5\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
        "\n",
        "        # Fully connected (dense) layers\n",
        "\n",
        "        # First fully connected layer: 16*5*5 input features, 120 output features\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
        "\n",
        "        # Second fully connected layer: 120 input features, 84 output features\n",
        "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
        "\n",
        "        # Third fully connected layer: 84 input features, 10 output features (for classification)\n",
        "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Forward pass through the neural network\n",
        "\n",
        "        # Apply first convolutional layer, followed by ReLU activation and max pooling\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "\n",
        "        # Apply second convolutional layer, followed by ReLU activation and max pooling\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # The output from the convolutional and pooling layers is in the form of a\n",
        "        # 3D tensor (height, width, depth or channels).\n",
        "        # To feed this tensor into a fully connected layer,\n",
        "        # it needs to be flattened into a 1D tensor.\n",
        "        # Reshape tensor for fully connected layers\n",
        "        # A2D tensor with a shape of [batch_size, 16 * 5 * 5].\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "\n",
        "        # Apply first fully connected layer, followed by ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "\n",
        "        # Apply second fully connected layer, followed by ReLU activation\n",
        "        x = F.relu(self.fc2(x))\n",
        "\n",
        "        # Apply third fully connected layer (output layer)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "heygH3k7ZI0L"
      },
      "outputs": [],
      "source": [
        "# A function to evaluate the performance of a given neural network model\n",
        "# using a test dataset.\n",
        "# It calculates the accuracy of the model's predictions on the test data.\n",
        "def calculate_accuracy(\n",
        "    model: nn.Module, dataloader: DataLoader, max_samples=None\n",
        ") -> float:\n",
        "    correct_predictions = 0  # Initialize the count of correctly predicted samples\n",
        "    total_samples = 0  # Initialize the count of total samples\n",
        "    inference_count = 0  # Initialize the count of inferences made\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation for inference\n",
        "        for batch_data in dataloader:\n",
        "            images, labels = batch_data  # Separate images and labels from the batch\n",
        "\n",
        "            images = images.to(device)  # Move images to the specified device\n",
        "            labels = labels.to(device)  # Move labels to the specified device\n",
        "\n",
        "            outputs = model(images)  # Forward pass to get model predictions\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get predicted class indices\n",
        "\n",
        "            total_samples += labels.size(0)  # Increment the total count of samples\n",
        "            correct_predictions += (\n",
        "                (predicted == labels).sum().item()\n",
        "            )  # Count correct predictions\n",
        "\n",
        "            if (\n",
        "                max_samples\n",
        "            ):  # Check if a maximum number of samples for testing is specified\n",
        "                inference_count += images.shape[\n",
        "                    0\n",
        "                ]  # Increment the count of inferences made\n",
        "                if (\n",
        "                    inference_count > max_samples\n",
        "                ):  # Stop testing if maximum samples reached\n",
        "                    break\n",
        "\n",
        "    accuracy = (\n",
        "        100 * correct_predictions / total_samples\n",
        "    )  # Calculate the accuracy as a percentage\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tIgKCdRcmB8"
      },
      "source": [
        "## DP Hyperparamters\n",
        "Here is where we will defined the different hyperparameters needed for DP-SGD.\n",
        "* $N = 2048$: Number of datapoints we are using. Since DP-SGD takes extremely long to run, we will only use a subset of the total CIFAR-10 dataset\n",
        "* $C = 1.0$: This is the clipping threshold. If $||∇L(x, y)||_{2} > C$ then we divide by $||∇L(x, y)||_{2}$.\n",
        "* $E = 20$: Number of epochs to run DP-SGD\n",
        "* $q = batch\\_size / N$: This is the sample probability. Since we are grouping the dataset into batches, each batch can be thought of as being sampled.\n",
        "* $T = \\frac{E}{q}$: number of iterations. This is more of an internal value used to calculate the DP parameter values, because DP-SGD is measured in terms of iterations, not epochs. But we can convert from Epochs to iterations.\n",
        "* $\\sigma$: The noise multiplier used to add noise to the gradients. As $\\sigma$ gets larger, the privacy guarantee improves but the variance of the noise increases, which can reduce the accuracy or utility. The choice of $\\sigma$ is often related to the desired $\\varepsilon$ value; achieving a lower\n",
        "$\\varepsilon$ (stronger privacy) typically requires a higher\n",
        "$\\sigma$.\n",
        "\n",
        "* $\\delta = 10^{-5}$: This is the probability of failure. We will set this to a default value.\n",
        "* $\\varepsilon = \\frac{q * \\sqrt{T * \\log(1 / \\delta)}}{\\sigma}$: the privacy loss, which is a function of the other hyperparameters. It quantifies the strength of the privacy guarantee. In DP, $\\varepsilon$ is used to define the level of indistinguishability that the algorithm ensures between outputs generated from datasets that differ by a single element. A smaller value means  a stronger privacy guarantee, meaning the outputs of the algorithm are more similar (indistinguishable) regardless of whether any individual's data is included or excluded from the dataset.\n",
        "However, a smaller value usually means more noise must be added to the data, which can degrade the utility or accuracy of the algorithm's output.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wUbCGtdL_UV"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "N = 2048\n",
        "C = 1.0\n",
        "E = 20\n",
        "q = batch_size / N\n",
        "T = E / q\n",
        "delta = 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhKzopgY_mbt",
        "outputId": "97ddd023-d342-41c8-9f4d-80b5bad41f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/drive/MyDrive/ML_Systems/HW6/data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29771504.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/ML_Systems/HW6/data/cifar-10-python.tar.gz to /content/drive/MyDrive/ML_Systems/HW6/data\n"
          ]
        }
      ],
      "source": [
        "# Define the mean values and standard deviation values for normalization\n",
        "mean_values = (0.5, 0.5, 0.5)  # Mean values for red, green, and blue channels\n",
        "std_values = (\n",
        "    0.5,\n",
        "    0.5,\n",
        "    0.5,\n",
        ")  # Standard deviation values for red, green, and blue channels\n",
        "\n",
        "# Define the transformation pipeline\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),  # Convert images to tensors\n",
        "        transforms.Normalize(mean_values, std_values),  # Normalize tensor values\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load the CIFAR10 training dataset and apply the defined transformations\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root=data_dir, train=True, download=True, transform=transform\n",
        ")\n",
        "\n",
        "trainsubset = torch.utils.data.Subset(trainset, torch.arange(N))\n",
        "\n",
        "# Create a DataLoader to efficiently load and process training data in batches\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainsubset, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN2J7UqXCo8j"
      },
      "source": [
        "## Non-Private Training with SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBu02M4lCo8j",
        "outputId": "8da40b75-020b-498d-b8e2-e72bef9ec7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 2.3020\n",
            "Epoch 2 loss: 2.3006\n",
            "Epoch 3 loss: 2.2974\n",
            "Epoch 4 loss: 2.2823\n",
            "Epoch 5 loss: 2.2019\n",
            "Epoch 6 loss: 2.0951\n",
            "Epoch 7 loss: 1.9962\n",
            "Epoch 8 loss: 1.9137\n",
            "Epoch 9 loss: 1.8426\n",
            "Epoch 10 loss: 1.7804\n",
            "Epoch 11 loss: 1.7222\n",
            "Epoch 12 loss: 1.6700\n",
            "Epoch 13 loss: 1.6180\n",
            "Epoch 14 loss: 1.5727\n",
            "Epoch 15 loss: 1.5318\n",
            "Epoch 16 loss: 1.4884\n",
            "Epoch 17 loss: 1.4438\n",
            "Epoch 18 loss: 1.4009\n",
            "Epoch 19 loss: 1.3529\n",
            "Epoch 20 loss: 1.3044\n",
            "Finished Training\n",
            "Accuracy of the network on the train images: 52.587890625%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def SGD(model, dataloader, lr):\n",
        "    # Define the loss criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "    # Loop over the dataset for multiple epochs\n",
        "    for epoch in range(E):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            output = model(inputs)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            running_loss += loss\n",
        "\n",
        "        print(f\"Epoch {epoch+1} loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")  # Training loop is complete\n",
        "\n",
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "SGD(net, trainloader, lr=0.05)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZZrJ9ZpgTrt"
      },
      "source": [
        "## Q1: Privacy-Aware Training with DP-SGD\n",
        "TODO: Change the naive SGD function to make it become differentially private. Please refer to the original [paper](https://arxiv.org/pdf/1607.00133.pdf) for DP-SGD alogrithm.\n",
        "\n",
        "Note that we have removed the pytorch optimizer. Instead, we'll be implementing the optimzer functionality ourselves.\n",
        "\n",
        "We set $\\sigma = 0.05$ and $lr = 0.05$. Note that this training loop has not converged to the optimal weights due to insufficient training epochs, but for simplicity, we stop training after 20 epochs. In practice, to get the optimal accuracy for DP-SGD, we need to run significantly more epochs than naive SGD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "LpdkuhRN03sb",
        "outputId": "a93e13b3-0d85-4731-8190-6d5b710ff0d6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-7a3d8416413c>\"\u001b[0;36m, line \u001b[0;32m41\u001b[0m\n\u001b[0;31m    with torch.no_grad():\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'with' statement on line 31\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "def DPSGD(model, dataloader, sigma, lr):\n",
        "    # Define the loss criterion and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "\n",
        "    # Loop over the dataset for multiple epochs\n",
        "    for epoch in range(E):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            for param in model.parameters():\n",
        "                param.accumulated_grads = torch.zeros_like(param)\n",
        "\n",
        "            # Iterate over each input sample and its corresponding label sample\n",
        "            per_batch_loss = 0.0\n",
        "            for input_sample, label_sample in zip(inputs, labels):\n",
        "                input_sample = input_sample.unsqueeze(0)\n",
        "                label_sample = label_sample.unsqueeze(0)\n",
        "\n",
        "                # TODO: Compute gradients per sample\n",
        "\n",
        "\n",
        "                # TODO: Accumulate per_sample_loss to per_batch_loss for debugging purpose\n",
        "\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # TODO: Clip gradients and add noise, then accumulate gradients\n",
        "\n",
        "\n",
        "                # TODO: Clear gradients\n",
        "\n",
        "\n",
        "            # TODO: Average per_batch_loss and accumulate it to running_loss for debug purpose\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # TODO: Averge accumulated gradients and update parameters\n",
        "                # Please use param.copy_() to set new param\n",
        "\n",
        "\n",
        "        print(f\"Epoch {epoch+1} loss: {running_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")  # Training loop is complete\n",
        "\n",
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "DPSGD(net, trainloader, sigma=0.05, lr=0.05)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "sigma = 0.05  # Noise parameter for privacy\n",
        "lr = 0.05  # Learning rate\n",
        "def DPSGD(model, dataloader, sigma, lr):\n",
        "    # Define the loss criterion\n",
        "    criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "\n",
        "    # Loop over the dataset for multiple epochs\n",
        "    for epoch in range(E):\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch in dataloader:\n",
        "            inputs, labels = batch\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Clear accumulated gradients\n",
        "            for param in model.parameters():\n",
        "                param.accumulated_grads = torch.zeros_like(param)\n",
        "\n",
        "            # Iterate over each input sample and its corresponding label sample\n",
        "            per_batch_loss = 0.0\n",
        "            for input_sample, label_sample in zip(inputs, labels):\n",
        "                input_sample = input_sample.unsqueeze(0)\n",
        "                label_sample = label_sample.unsqueeze(0)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_sample)\n",
        "                loss = criterion(outputs, label_sample)\n",
        "                per_batch_loss += loss.item()\n",
        "\n",
        "                # Compute gradients per sample\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip gradients (DP-SGD specific)\n",
        "                clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "                # Add noise to gradients and accumulate gradients (DP-SGD specific)\n",
        "                with torch.no_grad():\n",
        "                    for param in model.parameters():\n",
        "                        param.accumulated_grads += param.grad + torch.randn_like(param.grad) * sigma\n",
        "\n",
        "                # Clear gradients\n",
        "                model.zero_grad()\n",
        "\n",
        "            # Average per_batch_loss\n",
        "            per_batch_loss /= len(inputs)\n",
        "            running_loss += per_batch_loss\n",
        "\n",
        "            # Average accumulated gradients and update parameters (DP-SGD specific)\n",
        "            with torch.no_grad():\n",
        "                for param in model.parameters():\n",
        "                    param.copy_(param - lr * param.accumulated_grads / len(inputs))\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} loss: {running_loss / len(dataloader):.4f}\")\n",
        "\n",
        "    print(\"Finished Training\")\n",
        "\n",
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "DPSGD(net, trainloader, sigma, lr)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI8CNg5bllSA",
        "outputId": "8c2c6e99-efad-4a1d-e440-e7174ff35602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 2.3022\n",
            "Epoch 2 loss: 2.3006\n",
            "Epoch 3 loss: 2.2962\n",
            "Epoch 4 loss: 2.2815\n",
            "Epoch 5 loss: 2.2542\n",
            "Epoch 6 loss: 2.2172\n",
            "Epoch 7 loss: 2.1608\n",
            "Epoch 8 loss: 2.1158\n",
            "Epoch 9 loss: 2.0919\n",
            "Epoch 10 loss: 2.0755\n",
            "Epoch 11 loss: 2.0592\n",
            "Epoch 12 loss: 2.0442\n",
            "Epoch 13 loss: 2.0302\n",
            "Epoch 14 loss: 2.0160\n",
            "Epoch 15 loss: 2.0033\n",
            "Epoch 16 loss: 1.9933\n",
            "Epoch 17 loss: 1.9821\n",
            "Epoch 18 loss: 1.9742\n",
            "Epoch 19 loss: 1.9661\n",
            "Epoch 20 loss: 1.9561\n",
            "Finished Training\n",
            "Accuracy of the network on the train images: 30.810546875%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pMMDA_lCo8j"
      },
      "source": [
        "## Q2: Privacy and utility trade-off\n",
        "\n",
        "TODO: Plot how $\\epsilon$ changes as $\\sigma$ is increasing from 0.01 to 1. For the rest of the DP-SGD hyperparameters, use the default values defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQ9GObu4Co8k"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "sigma_values = np.linspace(0.01, 1, 100)\n",
        "epsilon_values = []\n",
        "\n",
        "# TODO: calculate epsilon values for each sigma value based on the formula\n",
        "\n",
        "\n",
        "# Plot sigma vs epsilon\n",
        "plt.plot(sigma_values, epsilon_values)\n",
        "plt.xlabel(\"Sigma\")\n",
        "plt.ylabel(\"Epsilon\")\n",
        "plt.title(\"Sigma vs Epsilon\")\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_values = np.linspace(0.01, 1, 100)\n",
        "epsilon_values = []\n",
        "\n",
        "epsilon = 2 * np.log(1.25 / delta) * sensitivity / (sigma * np.sqrt(N))\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define privacy parameters\n",
        "delta = 1e-5  # Desired privacy level (e.g., 1e-5 for 10^-5)\n",
        "N = 1000  # Size of the dataset (number of samples)\n",
        "sensitivity = 1  # Default sensitivity (assumed)\n",
        "\n",
        "# Define sigma values\n",
        "sigma_values = np.linspace(0.01, 1, 100)\n",
        "epsilon_values = []\n",
        "\n",
        "# Calculate epsilon values for each sigma value\n",
        "for sigma in sigma_values:\n",
        "    epsilon = 2 * np.log(1.25 / delta) * sensitivity / (sigma * np.sqrt(N))\n",
        "    epsilon_values.append(epsilon)\n",
        "\n",
        "# Plot sigma vs epsilon\n",
        "plt.plot(sigma_values, epsilon_values)\n",
        "plt.xlabel(\"Sigma\")\n",
        "plt.ylabel(\"Epsilon\")\n",
        "plt.title(\"Sigma vs Epsilon\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "5URrK850j5vS",
        "outputId": "b627ec98-86f2-437a-d7b2-d406bc086b8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2dcImlDSrgA"
      },
      "source": [
        "TODO: Run DP-SGD again with $\\sigma=0.1$ and compare accuracy with the previous experiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuCnSlO_S9KJ",
        "outputId": "cde87705-947d-4703-af9b-bc7da724cdeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 2.3013\n",
            "Epoch 2 loss: 2.2960\n",
            "Epoch 3 loss: 2.2813\n",
            "Epoch 4 loss: 2.2573\n",
            "Epoch 5 loss: 2.2225\n",
            "Epoch 6 loss: 2.1828\n",
            "Epoch 7 loss: 2.1486\n",
            "Epoch 8 loss: 2.1226\n",
            "Epoch 9 loss: 2.1086\n",
            "Epoch 10 loss: 2.0958\n",
            "Epoch 11 loss: 2.0845\n",
            "Epoch 12 loss: 2.0771\n",
            "Epoch 13 loss: 2.0750\n",
            "Epoch 14 loss: 2.0664\n",
            "Epoch 15 loss: 2.0585\n",
            "Epoch 16 loss: 2.0526\n",
            "Epoch 17 loss: 2.0461\n",
            "Epoch 18 loss: 2.0432\n",
            "Epoch 19 loss: 2.0392\n",
            "Epoch 20 loss: 2.0369\n",
            "Finished Training\n",
            "Accuracy of the network on the train images: 30.6640625%\n"
          ]
        }
      ],
      "source": [
        "# Create model and start training\n",
        "net = Net().to(device)\n",
        "DPSGD(net, trainloader, sigma=0.1, lr=0.05)\n",
        "\n",
        "score = calculate_accuracy(net, trainloader)\n",
        "print('Accuracy of the network on the train images: {}%'.format(score))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBn3Y939kE2P"
      },
      "source": [
        "TODO:\n",
        "How would privacy guarantee and model accuracy change when we increase the value of $\\sigma$?\n",
        "\n",
        "When you increase the value of `σ` (sigma) in differential privacy mechanisms like DP-SGD, several aspects related to privacy and model accuracy are affected:\n",
        "\n",
        "1. **Privacy Guarantee**:\n",
        "\n",
        "   - **Increased Privacy**: A larger `σ` implies increased noise added to the gradients during each training step. As a result, the privacy guarantee becomes stronger. The higher the `σ`, the more privacy is provided, as the added noise makes it harder to infer details about individual data points.\n",
        "\n",
        "   - **Reduced Privacy Budget Consumption**: With a larger `σ`, you can achieve the same level of privacy (e.g., ε-differential privacy) while consuming less of your privacy budget. This means you can perform more iterations or have a smaller privacy budget for the same level of privacy.\n",
        "\n",
        "2. **Model Accuracy**:\n",
        "\n",
        "   - **Decreased Accuracy**: Increasing `σ` leads to noisier gradient updates. This noise hinders the model's ability to fit the training data accurately. As a result, the model's convergence becomes slower, and its final accuracy may be lower compared to a non-private model (or a DP-SGD model with a smaller `σ`).\n",
        "\n",
        "   - **Trade-off**: There is a trade-off between privacy and model accuracy. When you increase `σ` for stronger privacy, you typically sacrifice some model accuracy. This trade-off can be managed by selecting an appropriate `σ` value based on your privacy requirements and the acceptable level of accuracy loss.\n",
        "\n",
        "   Reference: Given paper and Gpt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qe833eBCo8k"
      },
      "source": [
        "## Q3: System cost\n",
        "\n",
        "TODO: Why is DP-SGD computation much slower than SGD?\n",
        "\n",
        "TODO: For the naive SGD, if there are $P$ trainable parameters, we know that we need to store $P$ gradients during each batch iteration. How many gradients need to store for DP-SGD during each batch iteration?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DP-SGD computation is typically much slower than traditional SGD (Stochastic Gradient Descent) due to the additional steps required to ensure differential privacy and the introduction of noise in the gradient updates. Here's why DP-SGD is slower:\n",
        "\n",
        "1. **Noise Addition**: In DP-SGD, noise is added to the gradients during each batch iteration to ensure differential privacy. This noise is necessary to protect the privacy of individual data points in the training dataset. The addition of noise introduces randomness into the gradient updates, making the convergence slower.\n",
        "\n",
        "2. **Gradients Accumulation**: In DP-SGD, instead of updating the model parameters after each sample, gradients are accumulated over a batch of samples before updating the parameters. This accumulation step is essential for accurate privacy guarantees but adds computational overhead.\n",
        "\n",
        "3. **Clipping**: Gradients are typically clipped to limit their norm during each batch iteration in DP-SGD. This clipping step is crucial for ensuring that the noise added to the gradients does not excessively dominate the updates.\n",
        "\n",
        "4. **Parameter Updates**: After accumulating gradients over a batch and adding noise, model parameters are updated. The noise and accumulation steps introduce additional computational complexity compared to traditional SGD.\n",
        "\n",
        "5. **Privacy Budget Management**: To ensure differential privacy, a privacy budget must be managed across multiple iterations. This involves tracking and accounting for the cumulative privacy loss, which adds complexity and can limit the number of iterations.\n",
        "\n",
        "Regarding the number of gradients stored during each batch iteration:\n",
        "\n",
        "- In naive SGD, you need to store gradients for all trainable parameters during each batch iteration. If you have `P` trainable parameters, you need to store and compute `P` gradients.\n",
        "\n",
        "- In DP-SGD, you still need to store gradients for all trainable parameters during each batch iteration. The difference is in how these gradients are used. They are accumulated over the batch of samples before being averaged and used to update the model parameters. The accumulation step introduces additional computational overhead, but the number of gradients stored remains the same, i.e., `P` gradients. However, each gradient is subject to noise and clipping as part of the DP-SGD process.\n",
        "\n",
        "Reference: Given paper and Gpt\n"
      ],
      "metadata": {
        "id": "pFK_e_GRqtHK"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}